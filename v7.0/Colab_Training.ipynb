{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjJxipJeo0cA"
      },
      "source": [
        "## osumapper: create osu! map using Tensorflow and Colab\n",
        "\n",
        "### Model Training\n",
        "\n",
        "Github: https://github.com/kotritrona/osumapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EroyvoE7qr_P"
      },
      "source": [
        "### Step 0: Installation\n",
        "\n",
        "First of all, check the Notebook Settings under Edit tab.<br>\n",
        "Activate GPU to make the training faster.\n",
        "\n",
        "Then, clone the git repository and install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3APpbRI8qrxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1d0ab6-0ab5-4ce3-b298-2dbdcfd61ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'osumapper'...\n",
            "remote: Enumerating objects: 181, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 181 (delta 6), reused 16 (delta 2), pack-reused 159 (from 1)\u001b[K\n",
            "Receiving objects: 100% (181/181), 42.54 MiB | 19.79 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/sknctk/osumapper.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd osumapper/v7.0\n",
        "!apt install -y ffmpeg\n",
        "!apt install -y nodejs\n",
        "!cp requirements_colab.txt requirements.txt\n",
        "!cp package_colab.json package.json"
      ],
      "metadata": {
        "id": "a0Tb1oMfo9uR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b40703-6ff9-49d1-f194-e3767bb3af31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/osumapper/v7.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "nodejs is already the newest version (18.20.5-1nodesource1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get remove -y nodejs libnode72\n",
        "!sudo apt-get autoremove -y\n",
        "!sudo apt-get clean\n",
        "!curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -\n",
        "!sudo apt-get install -y nodejs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPPHMhxLASmY",
        "outputId": "eb013d36-e48a-4ef1-c96e-b8f6336d9a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package 'libnode72' is not installed, so not removed\n",
            "The following packages will be REMOVED:\n",
            "  nodejs\n",
            "0 upgraded, 0 newly installed, 1 to remove and 52 not upgraded.\n",
            "After this operation, 187 MB disk space will be freed.\n",
            "(Reading database ... 128965 files and directories currently installed.)\n",
            "Removing nodejs (18.20.5-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n",
            "\u001b[38;5;79m2024-12-04 14:15:07 - Installing pre-requisites\u001b[0m\n",
            "Hit:1 https://deb.nodesource.com/node_18.x nodistro InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.19).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.1).\n",
            "apt-transport-https is already the newest version (2.4.13).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://deb.nodesource.com/node_18.x nodistro InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\u001b[1;34m2024-12-04 14:15:17 - Repository configured successfully.\u001b[0m\n",
            "\u001b[38;5;79m2024-12-04 14:15:17 - To install Node.js, run: apt-get install nodejs -y\u001b[0m\n",
            "\u001b[38;5;79m2024-12-04 14:15:17 - You can use N|solid Runtime as a node.js alternative\u001b[0m\n",
            "\u001b[1;32m2024-12-04 14:15:17 - To install N|solid Runtime, run: apt-get install nsolid -y \n",
            "\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 29.6 MB of archives.\n",
            "After this operation, 187 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_18.x nodistro/main amd64 nodejs amd64 18.20.5-1nodesource1 [29.6 MB]\n",
            "Fetched 29.6 MB in 0s (66.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 123647 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_18.20.5-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (18.20.5-1nodesource1) ...\n",
            "Setting up nodejs (18.20.5-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!npm install"
      ],
      "metadata": {
        "id": "nHgvsGpMo8fX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372e90bd-aafc-4c27-be50-0b8f0de32eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: numpy==1.22.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.22.3)\n",
            "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: tensorflow>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.13.1)\n",
            "Requirement already satisfied: scikit_learn==1.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0->-r requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0->-r requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0->-r requirements.txt (line 1)) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0->-r requirements.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 3)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.1.3->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (1.68.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (3.12.1)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.1->-r requirements.txt (line 4)) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.13.1->-r requirements.txt (line 4)) (0.45.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.43.0->librosa==0.8.0->-r requirements.txt (line 1)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 1)) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.9.0->librosa==0.8.0->-r requirements.txt (line 1)) (1.17.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0->-r requirements.txt (line 1)) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.13.1->-r requirements.txt (line 4)) (3.2.2)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "up to date, audited 6 packages in 731ms\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPYxl6l4o18u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76KQyHYgrFEy"
      },
      "source": [
        "### Step 1: Upload training maps\n",
        "\n",
        "Write the maplist.txt and run the first block of `01_Training.ipynb` (`act_data_prep.step1_load_maps()`) locally.<br>\n",
        "After that, make a folder `NPZ/` under your google drive, and upload the generated npz files under local `mapdata/` in there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFWVEtE2vtoT"
      },
      "outputs": [],
      "source": [
        "# Wait for the upload to finish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83RcU3yap-N_"
      },
      "source": [
        "Mount your google drive in Colaboratory.<br>\n",
        "It will ask you for an auth code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF6WtFFupmyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415d25f4-ceb9-49ed-eec9-7dc0269244f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OjRVBotq9A7"
      },
      "source": [
        "Copy .npz files to the training data folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx9X_LIZqGGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce13691-a961-4124-e8e6-520f155a7e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'mapdata/*.npz': No such file or directory\n",
            "cp: cannot stat '/gdrive/My Drive/NPZ/*.npz': No such file or directory\n",
            "Copy complete!\n"
          ]
        }
      ],
      "source": [
        "# One of mkdir or rm will pop an error. Ignore it.\n",
        "!mkdir mapdata/\n",
        "!rm mapdata/*.npz\n",
        "!cp /gdrive/'My Drive'/NPZ/*.npz mapdata/\n",
        "print(\"Copy complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNQZjKoer8Fy"
      },
      "source": [
        "## Step 2: rhythm model\n",
        "\n",
        "(after this point it's copypaste from `01_Training.ipynb` from the second block)\n",
        "\n",
        "Train a rhythm model that decides where to place circles/sliders based on music.\n",
        "\n",
        "If you're using GPU and it reports a memory error, try setting batch_size parameter to a smaller value (that GPU can handle)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svgt9Fs2r7iy"
      },
      "outputs": [],
      "source": [
        "from act_train_rhythm import *;\n",
        "\n",
        "train_params = {\n",
        "    \"divisor\" : 4,\n",
        "    \"train_epochs\" : 32,\n",
        "    \"train_batch_size\" : None, # Default is 32 or based on machine specs\n",
        "    \"plot_history\" : True,\n",
        "    \"too_many_maps_threshold\" : 240,\n",
        "    \"train_epochs_many_maps\" : 12,\n",
        "    \"data_split_count\" : 80\n",
        "};\n",
        "model = step2_build_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv88gsdasKYh"
      },
      "source": [
        "Train the model and evaluate.\n",
        "is_note_start accuracy should be about 0.8 to 0.9 based on my tests, others should be lower.\n",
        "\n",
        "**Note:** I changed the metrics from F1 to AUC in this version!! 0.5=guessing 1=perfect for AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4IAxnpUqqy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851ea4bb-dae3-4154-9cbe-df6ba8b18fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "8/8 [==============================] - 1s 10ms/step\n",
            "is_note_start auc score: 0.8925388642448948\n",
            "is_circle auc score: 0.865718932072604\n",
            "is_slider auc score: 0.941004939184104\n",
            "is_note_end auc score: 0.7852706238810082\n"
          ]
        }
      ],
      "source": [
        "model = step2_train_model(model, train_params)\n",
        "step2_evaluate(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNxOeuT2sOz5"
      },
      "source": [
        "Done! now save the model to the disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPnmz5twsPOJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fbe68780-173e-4a54-e783-636fa19a1f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/osumapper/v7.0/act_train_rhythm.py:321: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  tf.keras.models.save_model(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c621ead0-8545-41c5-9292-ebee267b6197\", \"saved_rhythm_model\", 1278848)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "step2_save(model)\n",
        "\n",
        "files.download(\"saved_rhythm_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfeE3AjbsVoi"
      },
      "source": [
        "## Step 3: flow dataset construction\n",
        "\n",
        "Construct a dataset for the map flow generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxUhLFoEsWRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66348354-2b10-41f5-decd-9b5b86f0ed69"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_56101bcc-4d66-4363-8e4a-80b2a8e3867d\", \"flow_dataset.npz\", 5615536)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from act_flow_ds import *;\n",
        "\n",
        "flow_dataset_params = step3_set_params(note_group_size=10, step_size=5);\n",
        "maps_flow = step3_read_maps_flow(flow_dataset_params);\n",
        "step3_save_flow_dataset(maps_flow);\n",
        "files.download(\"flow_dataset.npz\")\n",
        "\n",
        "# hitsounds dataset, only for taiko maps\n",
        "# maps_hs_af, maps_hs = step3_read_maps_hs(flow_dataset_params);\n",
        "# step3_save_hs_dataset(maps_hs_af, maps_hs);\n",
        "# files.download(\"hs_dataset.npz\")\n",
        "\n",
        "# pattern dataset, only for mania (remove the flow part for mania)\n",
        "# data = step3_read_maps_pattern([]);\n",
        "# step3_save_pattern_dataset(data);\n",
        "# files.download(\"mania_pattern_dataset.npz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsGdBZ-UtPVk"
      },
      "source": [
        "Replace the default model files to use it in Colab map creator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSI3WWi_tPqY"
      },
      "outputs": [],
      "source": [
        "!cp saved_rhythm_model models/default/rhythm_model\n",
        "!cp flow_dataset.npz models/default/flow_dataset.npz\n",
        "# !cp hs_dataset.npz models/default/hs_dataset.npz\n",
        "# !cp mania_pattern_dataset.npz models/default/mania_pattern_dataset.npz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_pA6cIusoXQ"
      },
      "source": [
        "That's it! The models are trained. Start making a new map with the other notebook.\n",
        "\n",
        "For bug reports and feedbacks either report it on github or use discord: <br>\n",
        "[https://discord.com/invite/npmSy7K](https://discord.com/invite/npmSy7K)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}